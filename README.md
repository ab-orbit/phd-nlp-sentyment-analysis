# An√°lise de Sentimentos - NLP

Projeto de classifica√ß√£o de sentimentos comparando **4 abordagens de NLP** desde t√©cnicas cl√°ssicas (2000s) at√© m√©todos modernos (2024), demonstrando a evolu√ß√£o do processamento de linguagem natural.

## **Autor:** Jefferson Wellington da Cunha (jwc@)
## Doutorado em Engenharia de Software - CESAR - Centro de Estudos e Sistemas Avan√ßados do Recife
## **Sponsored by** Aeon Bridge Co.
## **Lab:** lab2@
## **Dataset:** Yelp Restaurant Reviews (38,000 avalia√ß√µes)

---

## Objetivos

Este projeto implementa e compara 4 abordagens distintas para classifica√ß√£o de sentimentos:

1. **SVM + Bag of Words (BoW)** - Baseline cl√°ssica (2000s)
2. **SVM + Word Embeddings** - Representa√ß√£o sem√¢ntica (2013-2017)
3. **BERT Fine-tuning** - Transformers com embeddings contextuais (2018-2022)
4. **In-Context Learning** - LLMs com zero/few-shot learning (2023+)

Cada abordagem √© avaliada com m√©tricas completas (Acur√°cia, Precision, Recall, F1-Score) e an√°lise de trade-offs (performance vs custo vs lat√™ncia).

---

## üìì Notebooks

### Implementa√ß√µes Principais

1. **`svm_bow.ipynb`** - SVM + Bag of Words
   - Acur√°cia: **89.92%** 
   - T√©cnica: Vetores esparsos de contagem de palavras
   - Treino: ~10 minutos (CPU)
   - Melhor para: Produ√ß√£o em alta escala, baixo custo

2. **`svm_embeddings.ipynb`** - SVM + Word2Vec Embeddings
   - Acur√°cia: **90.67%** 
   - T√©cnica: Vetores densos com sem√¢ntica
   - Treino: ~30-60 minutos (CPU)
   - Melhor para: Balan√ßo entre performance e simplicidade

3. **`bert_approach.ipynb`** - BERT Fine-tuning
   - Acur√°cia: **94.04%** 
   - T√©cnica: Transformers com embeddings contextuais
   - Treino: ~2-4 horas (GPU recomendada)
   - Melhor para: M√°xima performance
   - ‚ú® **Suporta Apple Silicon (MPS)** para Mac M1/M2/M3/M4

4. **`in_context_learning_approach.ipynb`** - LLMs (Zero/Few-shot)
   - Acur√°cia: **94.00%**  (Zero-Shot)
   - T√©cnica: Prompting de LLMs (GPT, Claude, Llama)
   - Treino: **N√£o requer** (zero-shot poss√≠vel)
   - Melhor para: Prototipagem r√°pida, poucos dados
   - **Suporta LM Studio local** (gratuito)

### An√°lise e Consolida√ß√£o

5. **`summary.ipynb`** - **Apresenta√ß√£o Consolidada**
   - Compara√ß√£o completa das 4 abordagens
   - Visualiza√ß√µes de performance e trade-offs
   - Matriz de decis√£o por cen√°rio de uso
   - Roadmap h√≠brido recomendado
   - Recomenda√ß√µes pr√°ticas
   - **Execute este notebook primeiro para vis√£o geral do projeto!**

---

## Setup do Ambiente

### Op√ß√£o 1: Usando UV (Recomendado)

```bash
# Instalar depend√™ncias
uv pip install transformers torch datasets accelerate scikit-learn matplotlib seaborn pandas numpy openai anthropic requests gensim ipywidgets

# Iniciar Jupyter
uv run jupyter lab
```

### Op√ß√£o 2: Script Automatizado

```bash
# Executar script de setup
./setup_clean_env.sh

# Ativar ambiente
source .venv/bin/activate

# Iniciar Jupyter
jupyter lab
```

### Op√ß√£o 3: Manual

```bash
# Criar ambiente virtual com uv
uv venv

# Ativar ambiente
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Instalar depend√™ncias
uv pip install -r requirements.txt

# Registrar kernel Jupyter
python -m ipykernel install --user --name=nlp-sentiment
```

---

## üóÇÔ∏è Estrutura do Projeto

```
sentiment-analysis/
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îî‚îÄ‚îÄ yelp_reviews.csv              # 38k avalia√ß√µes Yelp (bin√°rio)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ projeto-mod1.jpg
‚îÇ   ‚îî‚îÄ‚îÄ restaurantes_ativos_recife.csv
‚îú‚îÄ‚îÄ restaurant_reviews/               # Spider Scrapy (coleta de dados)
‚îÇ   ‚îî‚îÄ‚îÄ restaurant_reviews/
‚îÇ       ‚îî‚îÄ‚îÄ spiders/
‚îú‚îÄ‚îÄ svm_bow.ipynb                     # Abordagem 1: SVM + BoW (89.92%)
‚îú‚îÄ‚îÄ svm_embeddings.ipynb              # Abordagem 2: SVM + Embeddings (~91.5%)
‚îú‚îÄ‚îÄ bert_approach.ipynb               # Abordagem 3: BERT (~93.5%)
‚îú‚îÄ‚îÄ in_context_learning_approach.ipynb # Abordagem 4: ICL (~90%)
‚îú‚îÄ‚îÄ summary.ipynb                     # üìä Apresenta√ß√£o consolidada
‚îú‚îÄ‚îÄ requirements.txt                  # Depend√™ncias pip
‚îú‚îÄ‚îÄ pyproject.toml                    # Configura√ß√£o uv
‚îú‚îÄ‚îÄ uv.lock                          # Lock file uv
‚îú‚îÄ‚îÄ setup_clean_env.sh               # Script de setup
‚îú‚îÄ‚îÄ FIX_DEPENDENCIES.md              # Guia de troubleshooting
‚îú‚îÄ‚îÄ COMMON_ERRORS.md                 # Erros comuns e solu√ß√µes
‚îî‚îÄ‚îÄ README.md                        # Este arquivo
```

---

## üì¶ Depend√™ncias Principais

### Core ML/NLP
- **pandas**, **numpy** - Manipula√ß√£o de dados
- **scikit-learn** - SVM, m√©tricas, valida√ß√£o
- **gensim** - Word2Vec, embeddings

### Deep Learning
- **torch** - PyTorch (com suporte MPS para Mac)
- **transformers** - BERT, tokenizers (Hugging Face)
- **datasets**, **accelerate** - Utilidades Hugging Face

### LLMs (In-Context Learning)
- **openai** - API OpenAI (GPT-3.5/4) [opcional]
- **anthropic** - API Anthropic (Claude) [opcional]
- **requests** - Para LM Studio/Ollama local

### Visualiza√ß√£o & Jupyter
- **matplotlib**, **seaborn** - Gr√°ficos
- **ipywidgets** - Widgets interativos
- **jupyter**, **ipykernel** - Ambiente notebook

---

## Dataset

**Fonte:** Yelp Restaurant Reviews
**Tamanho:** 38,000 avalia√ß√µes
**Distribui√ß√£o:** Balanceada (19k negativas, 19k positivas)
**Formato:** CSV com 2 colunas (label, text)

### Labels
- **1** = Negativo (avalia√ß√£o ruim)
- **2** = Positivo (avalia√ß√£o boa)

### Caracter√≠sticas
- **Comprimento m√©dio:** 133 palavras por avalia√ß√£o
- **Range:** 4 a 5,093 caracteres
- **Idioma:** Ingl√™s
- **Dom√≠nio:** Restaurantes (comida, servi√ßo, atendimento)

---

## Uso

### Quick Start

1. **Clone o reposit√≥rio** (se aplic√°vel)
2. **Instale as depend√™ncias** (veja se√ß√£o Setup)
3. **Inicie Jupyter Lab**: `uv run jupyter lab`
4. **Comece pelo Summary**: Execute `summary.ipynb` para vis√£o geral
5. **Execute notebooks individuais** na ordem desejada

### Ordem Recomendada

**Para aprendizado:**
1. `svm_bow.ipynb` (mais simples)
2. `svm_embeddings.ipynb` (intermedi√°rio)
3. `bert_approach.ipynb` (avan√ßado)
4. `in_context_learning_approach.ipynb` (moderno)
5. `summary.ipynb` (consolida√ß√£o)

**Para decis√£o r√°pida:**
1. `summary.ipynb` (veja matriz de decis√£o)
2. Execute o notebook recomendado para seu caso

---

## Compara√ß√£o das Abordagens

| Abordagem | Acur√°cia | Treino | Hardware | Lat√™ncia | Custo/Inf | Quando Usar |
|-----------|----------|--------|----------|----------|-----------|-------------|
| **SVM + BoW** | 89.92% | 5-10 min | CPU | <1ms | Muito baixo | Produ√ß√£o em escala |
| **SVM + Embeddings** | 90.67% | 30-60 min | CPU | <10ms | Baixo | Balan√ßo performance/custo |
| **BERT** | 94.04% | 2-4h (GPU) | GPU/MPS | 50-100ms | M√©dio | M√°xima performance |
| **In-Context Learning** | 94.00% | **N√£o requer** | API/Local | 100-500ms | Alto | Prototipagem, poucos dados |

### Trade-offs Principais

**Performance:** BERT > SVM Embeddings > SVM BoW ‚âà ICL
**Velocidade:** SVM BoW > SVM Embeddings > BERT > ICL
**Custo Operacional:** SVM BoW > SVM Embeddings > BERT > ICL
**Facilidade Setup:** ICL > SVM BoW > SVM Embeddings > BERT
**Flexibilidade:** ICL > BERT > SVM Embeddings > SVM BoW

---

## Configura√ß√µes Especiais

### GPU no Mac (Apple Silicon)

Os notebooks BERT suportam **MPS (Metal Performance Shaders)** para acelera√ß√£o em GPU Apple:

```python
# Detec√ß√£o autom√°tica no notebook
if torch.backends.mps.is_available():
    device = torch.device('mps')  # Usa GPU do Mac
    print("‚úì Usando Apple Silicon GPU")
```

**Performance:** 10-50x mais r√°pido que CPU em Mac M1/M2/M3/M4

### LM Studio para In-Context Learning

O notebook `in_context_learning_approach.ipynb` suporta **LM Studio** (gratuito, local):

1. Instale LM Studio: https://lmstudio.ai
2. Baixe um modelo (ex: Llama 3.1)
3. Inicie o servidor na porta 11434
4. O notebook detecta automaticamente!

**Vantagem:** Zero custo, sem APIs pagas, dados privados

---

## Troubleshooting

### Erros Comuns

#### 1. ImportError: cannot import 'AdamW' from 'transformers'

**Solu√ß√£o:** AdamW foi movido para `torch.optim`
```python
from torch.optim import AdamW  # Correto
# from transformers import AdamW  # Deprecado
```

#### 2. TypeError: Cannot convert MPS Tensor to float64

**Solu√ß√£o:** MPS n√£o suporta float64, use float32
```python
# Use .float() ao inv√©s de .double()
accuracy = correct_predictions.float() / total
```

#### 3. KeyError: 'label' ao ler CSV

**Solu√ß√£o:** Adicione `header=None` ao ler o CSV
```python
df = pd.read_csv('dataset/yelp_reviews.csv',
                 names=['label', 'text'],
                 header=None)  # Importante!
```

#### 4. Conflitos de depend√™ncias

**Solu√ß√£o:** Use ambiente limpo com uv
```bash
uv venv --force
source .venv/bin/activate
uv pip install -r requirements.txt
```

#### 5. Kernel n√£o aparece no Jupyter

**Solu√ß√£o:**
```bash
python -m ipykernel install --user --name=nlp-sentiment --display-name "Python (NLP Sentiment)"
# Reinicie Jupyter Lab
```

#### 6. Out of Memory (GPU/MPS)

**Solu√ß√µes:**
- Reduzir `batch_size` (16 ‚Üí 8 ‚Üí 4)
- Reduzir `max_length` (128 ‚Üí 64)
- Usar CPU: `device = torch.device('cpu')`

#### 7. LM Studio n√£o detectado (In-Context Learning)

**Solu√ß√µes:**
- Verifique se servidor est√° rodando (porta 11434)
- Teste: `curl http://localhost:11434/v1/models`
- Instale pacotes: `uv pip install openai requests`

**Consulte:** `COMMON_ERRORS.md` para lista completa

---

## Dicas e Recomenda√ß√µes

### Para Estudantes/Pesquisadores
- Execute todos os 4 notebooks para entender a evolu√ß√£o do NLP
- Compare resultados e analise trade-offs
- Experimente com diferentes par√¢metros
- Use `summary.ipynb` para apresenta√ß√µes

### Para Profissionais/Produ√ß√£o
1. **MVP/Prototipagem:** Use In-Context Learning (setup em minutos)
2. **Produ√ß√£o em Escala:** Use SVM + BoW (custo m√≠nimo, lat√™ncia <1ms)
3. **Performance Cr√≠tica:** Use BERT fine-tuned (m√°xima acur√°cia)
4. **H√≠brido:** SVM para casos f√°ceis (80%), BERT para dif√≠ceis (20%)

### Pr√≥ximos Passos Sugeridos
- Implementar TF-IDF ao inv√©s de BoW (+1-2% acur√°cia)
- Adicionar n-gramas (bigramas, trigramas)
- Ensemble: combinar SVM + BERT
- Deploy com FastAPI
- Monitoramento de drift

---

## Recursos Adicionais

### Papers Fundamentais
- Joachims (1998) - Text Categorization with SVM
- Mikolov et al. (2013) - Word2Vec
- Vaswani et al. (2017) - Attention Is All You Need
- Devlin et al. (2018) - BERT
- Brown et al. (2020) - GPT-3 (Few-Shot Learning)

### Documenta√ß√£o
- Scikit-learn: https://scikit-learn.org/
- Hugging Face Transformers: https://huggingface.co/docs/transformers/
- PyTorch: https://pytorch.org/docs/
- Gensim: https://radimrehurek.com/gensim/

### Cursos Online
- Stanford CS224N: NLP with Deep Learning
- Fast.ai: Practical Deep Learning
- DeepLearning.AI: NLP Specialization

---

## Licen√ßa

Projeto acad√™mico - PhD Data Science
Universidade/Institui√ß√£o: CESAR


---

## ü§ù Contribui√ß√µes

Para d√∫vidas, sugest√µes ou contribui√ß√µes:
- Abra uma issue no reposit√≥rio
- Entre em contato com o autor: Jefferson Wellington Cunha (jwc@)
- contact@aeonbridge.com

---

**Dica Final:** Comece executando `summary.ipynb` para ter uma vis√£o completa do projeto e decidir qual abordagem explorar em detalhes!
