{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aktg9a0019s",
   "source": "# Classificação de Sentimentos com SVM + Word Embeddings\n\nEste notebook implementa um classificador de sentimentos para avaliações de estabelecimentos utilizando:\n- **SVM (Support Vector Machine)**: algoritmo de aprendizado supervisionado para classificação\n- **Word Embeddings**: representação vetorial densa de palavras que captura relações semânticas\n\n## Diferença entre BoW e Embeddings\n\n### Bag of Words (BoW)\n- Vetores esparsos de alta dimensionalidade\n- Cada palavra é independente (não captura relações semânticas)\n- Baseado em frequência de palavras\n\n### Word Embeddings\n- Vetores densos de menor dimensionalidade (tipicamente 50-300 dimensões)\n- Palavras similares têm vetores próximos no espaço vetorial\n- Captura relações semânticas e sintáticas\n- Exemplos: Word2Vec, GloVe, FastText\n\n## Objetivo\nClassificar avaliações de estabelecimentos como positivas ou negativas usando embeddings pré-treinados ou treinados no corpus.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "39y45hkis69",
   "source": "## 1. Importação de Bibliotecas\n\nImportando as bibliotecas necessárias para processamento de texto, embeddings, modelagem e avaliação.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "gnyxtjhrfcg",
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom gensim.models import Word2Vec\nfrom gensim.models.keyedvectors import KeyedVectors\nimport re\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configurações de visualização\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"Bibliotecas importadas com sucesso!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "um9s01q21nf",
   "source": "## 2. Carregamento dos Dados\n\nCarregando o dataset de avaliações do Yelp para análise e treinamento do modelo.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "751fj1j287",
   "source": "# Carregando o dataset do Yelp\ndf = pd.read_csv('dataset/yelp_reviews.csv', names=['label', 'text'])\n\nprint(f\"Dimensões do dataset: {df.shape}\")\nprint(f\"\\nDistribuição de classes:\")\nprint(df['label'].value_counts())\nprint(f\"\\nPrimeiras linhas:\")\ndf.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tef2g5esdm9",
   "source": "## 3. Exploração Inicial dos Dados\n\nVerificando a qualidade dos dados e identificando possíveis problemas.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "qn192y7pd4k",
   "source": "# Verificar valores nulos\nprint(\"Valores Nulos:\")\nprint(df.isnull().sum())\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Informações sobre o dataset\nprint(\"Informações do Dataset:\")\ndf.info()\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Estatísticas do comprimento dos textos\ndf['text_length'] = df['text'].apply(len)\ndf['word_count'] = df['text'].apply(lambda x: len(x.split()))\n\nprint(\"Estatísticas de Comprimento:\")\nprint(f\"Caracteres - Média: {df['text_length'].mean():.0f}, Mediana: {df['text_length'].median():.0f}\")\nprint(f\"Palavras - Média: {df['word_count'].mean():.0f}, Mediana: {df['word_count'].median():.0f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tbvopcjsbkd",
   "source": "## 4. Pré-processamento de Texto\n\nPara trabalhar com embeddings, o pré-processamento precisa manter a estrutura das palavras. Vamos:\n- Converter para minúsculas\n- Remover pontuação\n- Remover números\n- Tokenizar em palavras (importante para Word2Vec)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "69yoqlnrr0y",
   "source": "def preprocess_text(text):\n    \"\"\"\n    Função para pré-processar texto e retornar lista de palavras (tokens)\n    \"\"\"\n    # Converter para minúsculas\n    text = text.lower()\n    \n    # Remover números\n    text = re.sub(r'\\d+', '', text)\n    \n    # Remover pontuação\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # Remover espaços extras e tokenizar\n    tokens = text.split()\n    \n    return tokens\n\n# Aplicar pré-processamento\ndf['tokens'] = df['text'].apply(preprocess_text)\n\n# Verificar resultado\nprint(\"Exemplo de tokenização:\")\nprint(f\"Original: {df['text'].iloc[0][:150]}...\")\nprint(f\"\\nTokens: {df['tokens'].iloc[0][:20]}...\")\nprint(f\"\\nNúmero de tokens: {len(df['tokens'].iloc[0])}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dsloejx50yw",
   "source": "## 5. Treinamento de Word Embeddings com Word2Vec\n\nVamos treinar nosso próprio modelo Word2Vec no corpus de avaliações. Os parâmetros principais são:\n\n- **vector_size**: dimensão dos vetores (100 é um bom começo)\n- **window**: tamanho da janela de contexto (quantas palavras ao redor considerar)\n- **min_count**: frequência mínima de uma palavra para ser incluída no vocabulário\n- **workers**: número de threads para processamento paralelo\n- **sg**: algoritmo (0 = CBOW, 1 = Skip-gram)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ysokmarlbm",
   "source": "# Treinar modelo Word2Vec\nprint(\"Treinando modelo Word2Vec...\")\nw2v_model = Word2Vec(\n    sentences=df['tokens'].tolist(),\n    vector_size=100,\n    window=5,\n    min_count=2,\n    workers=4,\n    sg=1,  # Skip-gram\n    epochs=10,\n    seed=42\n)\n\nprint(f\"Modelo treinado com sucesso!\")\nprint(f\"Tamanho do vocabulário: {len(w2v_model.wv)}\")\nprint(f\"Dimensão dos vetores: {w2v_model.wv.vector_size}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "wydx4fm0och",
   "source": "### 5.1 Explorando os Embeddings Treinados\n\nVamos testar a qualidade dos embeddings verificando palavras similares e fazendo operações vetoriais.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "n76sr14e7f",
   "source": "# Testar palavras similares\ntest_words = ['good', 'bad', 'food', 'service', 'excellent', 'terrible']\n\nprint(\"Palavras mais similares:\")\nprint(\"=\"*70)\n\nfor word in test_words:\n    if word in w2v_model.wv:\n        similar = w2v_model.wv.most_similar(word, topn=5)\n        print(f\"\\n{word.upper()}:\")\n        for similar_word, score in similar:\n            print(f\"  - {similar_word}: {score:.4f}\")\n    else:\n        print(f\"\\n{word.upper()}: não encontrada no vocabulário\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "spuj6fzuykl",
   "source": "## 6. Criação de Vetores de Documentos\n\nPara usar embeddings de palavras em classificação de documentos, precisamos agregar os vetores das palavras em um único vetor por documento. Vamos usar a **média dos vetores** das palavras do documento.\n\nEstratégias de agregação:\n1. **Média**: somar todos os vetores e dividir pelo número de palavras\n2. **Média ponderada**: usar TF-IDF como peso\n3. **Max pooling**: pegar o máximo de cada dimensão\n4. **Doc2Vec**: treinar embeddings diretamente para documentos",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "8dek83k05lg",
   "source": "def document_vector(tokens, model):\n    \"\"\"\n    Calcula o vetor de um documento como a média dos vetores de suas palavras\n    \"\"\"\n    # Filtrar palavras que estão no vocabulário\n    valid_tokens = [token for token in tokens if token in model.wv]\n    \n    if len(valid_tokens) == 0:\n        # Se nenhuma palavra estiver no vocabulário, retornar vetor zero\n        return np.zeros(model.wv.vector_size)\n    \n    # Calcular média dos vetores\n    vectors = [model.wv[token] for token in valid_tokens]\n    return np.mean(vectors, axis=0)\n\n# Criar vetores para todos os documentos\nprint(\"Criando vetores de documentos...\")\ndoc_vectors = np.array([document_vector(tokens, w2v_model) for tokens in df['tokens']])\n\nprint(f\"Forma da matriz de features: {doc_vectors.shape}\")\nprint(f\"Número de documentos: {doc_vectors.shape[0]}\")\nprint(f\"Dimensão dos vetores: {doc_vectors.shape[1]}\")\nprint(f\"\\nExemplo de vetor (primeiros 10 valores):\")\nprint(doc_vectors[0][:10])",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "boykc6nsmo8",
   "source": "## 7. Divisão dos Dados em Treino e Teste\n\nDividindo o dataset em conjuntos de treino (80%) e teste (20%) com estratificação para manter a proporção de classes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dmv8fs5dquc",
   "source": "# Preparar features e labels\nX = doc_vectors\ny = df['label']\n\n# Dividir os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"Tamanho do conjunto de treino: {X_train.shape[0]} amostras\")\nprint(f\"Tamanho do conjunto de teste: {X_test.shape[0]} amostras\")\nprint(f\"Dimensão dos vetores: {X_train.shape[1]}\")\nprint(f\"\\nDistribuição de classes no treino:\")\nprint(y_train.value_counts())\nprint(f\"\\nDistribuição de classes no teste:\")\nprint(y_test.value_counts())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ldphlzapotg",
   "source": "## 8. Treinamento do Modelo SVM\n\nVamos treinar um SVM com os vetores densos gerados pelos embeddings. Diferente do BoW (esparso), aqui trabalhamos com vetores densos de menor dimensionalidade.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "a5ijkip7jp",
   "source": "# Treinar modelo SVM inicial\nprint(\"Treinando modelo SVM com kernel RBF...\")\nsvm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\nsvm_model.fit(X_train, y_train)\n\nprint(\"Modelo treinado com sucesso!\")\nprint(f\"\\nNúmero de vetores de suporte: {svm_model.n_support_}\")\nprint(f\"Vetores de suporte por classe: {dict(zip([1, 2], svm_model.n_support_))}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bplvek3w11v",
   "source": "### 8.1 Otimização de Hiperparâmetros com GridSearchCV\n\nVamos otimizar os hiperparâmetros do SVM para embeddings. Como os vetores são densos, kernels não-lineares (RBF) podem funcionar melhor.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jkj893w7zmk",
   "source": "# Definir grid de hiperparâmetros\nparam_grid = {\n    'C': [0.1, 1, 10, 100],\n    'kernel': ['linear', 'rbf'],\n    'gamma': ['scale', 'auto']\n}\n\n# Grid Search com validação cruzada\nprint(\"Executando Grid Search (pode levar alguns minutos)...\")\ngrid_search = GridSearchCV(\n    SVC(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='accuracy',\n    n_jobs=-1,\n    verbose=1\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(\"\\nMelhores parâmetros encontrados:\")\nprint(grid_search.best_params_)\nprint(f\"\\nMelhor score na validação cruzada: {grid_search.best_score_:.4f}\")\n\n# Usar o melhor modelo\nbest_svm = grid_search.best_estimator_",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3426dswgfe",
   "source": "## 9. Avaliação do Modelo\n\nAvaliando o desempenho do modelo otimizado no conjunto de teste.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "iglybqqaggn",
   "source": "# Fazer predições no conjunto de teste\ny_pred = best_svm.predict(X_test)\n\n# Calcular acurácia\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Acurácia no conjunto de teste: {accuracy:.4f} ({accuracy*100:.2f}%)\")\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Relatório de classificação completo\nprint(\"Relatório de Classificação:\")\nprint(classification_report(y_test, y_pred, target_names=['Negativo (1)', 'Positivo (2)']))\n\n# Matriz de confusão\ncm = confusion_matrix(y_test, y_pred)\nprint(\"\\nMatriz de Confusão:\")\nprint(cm)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "urda3lwob1",
   "source": "# Visualização da Matriz de Confusão\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n            xticklabels=['Negativo (1)', 'Positivo (2)'],\n            yticklabels=['Negativo (1)', 'Positivo (2)'])\nplt.title('Matriz de Confusão - SVM + Embeddings')\nplt.ylabel('Valor Real')\nplt.xlabel('Valor Predito')\nplt.tight_layout()\nplt.show()\n\n# Calcular métricas detalhadas\ntn, fp, fn, tp = cm.ravel()\nprint(f\"\\nVerdadeiros Negativos: {tn}\")\nprint(f\"Falsos Positivos: {fp}\")\nprint(f\"Falsos Negativos: {fn}\")\nprint(f\"Verdadeiros Positivos: {tp}\")\nprint(f\"\\nTaxa de Falso Positivo: {fp/(fp+tn):.4f}\")\nprint(f\"Taxa de Falso Negativo: {fn/(fn+tp):.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "coq4e9v7cy",
   "source": "## 10. Análise de Resultados e Predições\n\nTestando o modelo com exemplos novos e analisando erros.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "leyv92ygl89",
   "source": "# Função para predizer sentimento de novos textos\ndef predict_sentiment(text):\n    \"\"\"\n    Prediz o sentimento de um texto usando embeddings\n    \"\"\"\n    # Pré-processar e tokenizar\n    tokens = preprocess_text(text)\n    \n    # Criar vetor do documento\n    doc_vec = document_vector(tokens, w2v_model).reshape(1, -1)\n    \n    # Predizer\n    prediction = best_svm.predict(doc_vec)[0]\n    \n    sentiment = \"Positivo\" if prediction == 2 else \"Negativo\"\n    return sentiment, prediction\n\n# Testar com exemplos novos\ntest_reviews = [\n    \"This place is amazing! Best food I've ever had. Highly recommend!\",\n    \"Terrible service, cold food, and overpriced. Never coming back.\",\n    \"It was okay, nothing special but not bad either.\",\n    \"Absolutely loved it! The staff was friendly and the atmosphere was great.\",\n    \"Worst experience ever. Waited for an hour and the food was disgusting.\"\n]\n\nprint(\"Predições para Novos Textos:\")\nprint(\"=\"*70)\nfor i, review in enumerate(test_reviews, 1):\n    sentiment, label = predict_sentiment(review)\n    print(f\"\\n{i}. Texto: {review}\")\n    print(f\"   Sentimento: {sentiment} (label={label})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3p9lv0y561w",
   "source": "### 10.1 Análise de Erros\n\nExaminar exemplos onde o modelo cometeu erros.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zs9ejy1a2kc",
   "source": "# Identificar predições incorretas\nincorrect_predictions = y_test != y_pred\nincorrect_indices = y_test[incorrect_predictions].index\n\nprint(f\"Total de predições incorretas: {incorrect_predictions.sum()}\")\nprint(f\"Taxa de erro: {incorrect_predictions.sum() / len(y_test):.4f}\\n\")\n\n# Mostrar alguns exemplos de erros\nprint(\"Exemplos de Classificações Incorretas:\")\nprint(\"=\"*70)\n\nnum_examples = min(5, len(incorrect_indices))\nfor i, idx in enumerate(incorrect_indices[:num_examples], 1):\n    true_label = y_test.loc[idx]\n    pred_label = y_pred[list(y_test.index).index(idx)]\n    text = df.loc[idx, 'text']\n    \n    true_sentiment = \"Positivo\" if true_label == 2 else \"Negativo\"\n    pred_sentiment = \"Positivo\" if pred_label == 2 else \"Negativo\"\n    \n    print(f\"\\nExemplo {i}:\")\n    print(f\"Texto: {text[:200]}...\")\n    print(f\"Real: {true_sentiment} ({true_label}) | Predito: {pred_sentiment} ({pred_label})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "560pngq3x6e",
   "source": "## 11. Comparação: Embeddings vs Bag of Words\n\nVamos comparar as principais diferenças entre as duas abordagens.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "c1kp84x5nf",
   "source": "# Criar tabela comparativa\ncomparison_data = {\n    'Aspecto': [\n        'Tipo de Vetor',\n        'Dimensionalidade',\n        'Esparsidade',\n        'Captura Semântica',\n        'Contexto',\n        'Vocabulário OOV',\n        'Tempo de Treinamento',\n        'Interpretabilidade'\n    ],\n    'Bag of Words': [\n        'Esparso',\n        'Alta (5000+ features)',\n        'Muito esparso (>95% zeros)',\n        'Não',\n        'Ignora ordem e contexto',\n        'Vetor zero',\n        'Rápido (apenas contagem)',\n        'Alta (features = palavras)'\n    ],\n    'Word Embeddings': [\n        'Denso',\n        'Baixa (100-300 features)',\n        'Denso (sem zeros)',\n        'Sim',\n        'Captura contexto local',\n        'Média de palavras conhecidas',\n        'Lento (treinar Word2Vec)',\n        'Média (features abstratas)'\n    ]\n}\n\ncomparison_df = pd.DataFrame(comparison_data)\n\nprint(\"Comparação: SVM + BoW vs SVM + Embeddings\")\nprint(\"=\"*80)\nprint(comparison_df.to_string(index=False))\nprint(\"\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "k993te8c7b",
   "source": "## 12. Conclusões\n\n### Resumo do Modelo\n- **Algoritmo**: Support Vector Machine (SVM) com kernel otimizado\n- **Representação**: Word2Vec embeddings (100 dimensões)\n- **Dataset**: Avaliações do Yelp com classificação binária (positivo/negativo)\n- **Agregação**: Média dos vetores de palavras por documento\n\n### Vantagens dos Embeddings\n1. **Captura semântica**: Palavras similares têm vetores próximos (ex: \"good\" e \"great\")\n2. **Menor dimensionalidade**: 100 features vs 5000+ do BoW\n3. **Vetores densos**: Toda informação é utilizada (sem esparsidade)\n4. **Generalização**: Melhor performance em palavras raras devido ao contexto\n5. **Transferência de aprendizado**: Pode usar embeddings pré-treinados (GloVe, FastText)\n\n### Desvantagens dos Embeddings\n1. **Tempo de treinamento**: Word2Vec precisa ser treinado ou carregado\n2. **Complexidade**: Mais difícil de interpretar que BoW\n3. **Agregação**: Perda de informação ao calcular média dos vetores\n4. **Dependência de corpus**: Embeddings treinados no próprio corpus podem ter vocabulário limitado\n\n### Quando usar cada abordagem?\n\n**Use BoW quando:**\n- Velocidade é crítica\n- Dataset é grande e vocabulário é rico\n- Interpretabilidade é importante\n- Recursos computacionais são limitados\n\n**Use Embeddings quando:**\n- Qualidade semântica é importante\n- Dataset é menor ou tem palavras raras\n- Quer aproveitar embeddings pré-treinados\n- Pode usar técnicas mais avançadas (CNN, LSTM)\n\n### Próximos Passos\n1. Experimentar com embeddings pré-treinados (GloVe, FastText)\n2. Testar agregações diferentes (TF-IDF weighted average, max pooling)\n3. Usar Doc2Vec para embeddings de documentos\n4. Comparar com modelos de deep learning (LSTM, Transformers)\n5. Combinar BoW e Embeddings (ensemble)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}